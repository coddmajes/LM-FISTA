{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c606124c",
   "metadata": {},
   "source": [
    "# Preprocess Yale Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0639a230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement opencv-python==3.4.8.29 (from versions: 3.4.0.14, 3.4.10.37, 3.4.11.39, 3.4.11.41, 3.4.11.43, 3.4.11.45, 3.4.13.47, 3.4.14.51, 3.4.14.53, 3.4.15.55, 3.4.16.57, 3.4.16.59, 3.4.17.61, 3.4.17.63, 4.3.0.38, 4.4.0.40, 4.4.0.42, 4.4.0.44, 4.4.0.46, 4.5.1.48, 4.5.2.52, 4.5.2.54, 4.5.3.56, 4.5.4.58, 4.5.4.60, 4.5.5.62, 4.5.5.64)\u001b[0m\n",
      "\u001b[31mERROR: No matching distribution found for opencv-python==3.4.8.29\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U opencv-python==3.4.8.29"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4108a1c5",
   "metadata": {},
   "source": [
    "## crop image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d318e018",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mbisect\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mcv\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m \n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpathlib\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import random\n",
    "from PIL import Image\n",
    "import bisect\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 as cv\n",
    "import numpy as np \n",
    "import pathlib\n",
    "import zipfile\n",
    "from PIL import Image,ImageFilter\n",
    "from scipy import ndimage,misc\n",
    "import os, random, shutil, fnmatch\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "from math import sqrt\n",
    "\n",
    "\n",
    "\n",
    "def gammaFunc(cImage):\n",
    "    gammaImage = np.power(cImage/float(np.max(cImage)), 1.2)\n",
    "    return gammaImage\n",
    "\n",
    "\n",
    "# 画素値を足し積み上げた1次元配列を作る．\n",
    "def BuildupPixelValue(array, size):\n",
    "    buildupArray = array.ravel().astype(np.uint32)\n",
    "    for i in range(1, size):\n",
    "        buildupArray[i] = buildupArray[i-1] + buildupArray[i]\n",
    "        #print(buildupArray[i])\n",
    "    return buildupArray\n",
    "\n",
    "\n",
    "# 画像を読み込むフォルダの指定．filenameに拡張子を除いた細胞画像名を指定する\n",
    "\n",
    "# here is for the original dataset\n",
    "test_dir = ''\n",
    "\n",
    "root_dir = os.walk(test_dir)\n",
    "crop = 200\n",
    "crop_w = crop//2\n",
    "\n",
    "for path, dir_list,file_list in root_dir:\n",
    "    for file_name in file_list:\n",
    "\n",
    "        path_incell = os.path.join(path, file_name)\n",
    "\n",
    "        path_outcell = os.path.join(path, \"crop/\"+file_name)\n",
    "        if not os.path.exists(os.path.join(path, \"crop/\")):\n",
    "                  print(os.path.join(path, \"crop/\"))\n",
    "                  os.makedirs(os.path.join(path, \"crop/\"))\n",
    "\n",
    "\n",
    "        # 細胞画像をfloat型の3次元配列として読み込む．\n",
    "        cellImage = np.array(Image.open(path_incell), np.float)\n",
    "        #array=cellImage.astype( np.uint8 )\n",
    "        #cannyImage = cv.Canny(array, 100, 200)\n",
    "        \n",
    "        # 表示\n",
    "        #plt.title('original image')\n",
    "        #plt.imshow(cellImage, plt.cm.gray)\n",
    "        \n",
    "        midx = 768//2\n",
    "        midy = 576//2\n",
    "        while cellImage[midy,midx]<30:\n",
    "            midx=midx+1\n",
    "        x0 = midx-crop_w\n",
    "        x1 = midx+crop_w-1\n",
    "        y0 = midy-85\n",
    "        y1 = midy+155-1\n",
    "                \n",
    "        # 細胞画像を切り出し．\n",
    "        crop_cellImage = np.zeros((crop, crop, 3), dtype=float)\n",
    "        # [row_start:row_stop:row_step, col_start:col_stop:col_step]  ！注意！行はy, 列はx\n",
    "        #print(cellImage[y0:y1+1, x0:x1+1, :].shape)\n",
    "        crop_cellImage = np.copy(cellImage[y0:y1+1, x0:x1+1])\n",
    "        # 保存\n",
    "        pil_crop_cellImage = Image.fromarray(crop_cellImage.astype(np.uint8))\n",
    "        pil_crop_cellImage.save(path_outcell)\n",
    "        # 表示\n",
    "        #plt.imshow(pil_crop_cellImage)\n",
    "        #plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97f6b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "expre_dir = \"./1210-test results/simulation_en_de0219/AR/val_se\"\n",
    "root_dir = os.walk(expre_dir)\n",
    "\n",
    "for path, dir_list,file_list in root_dir:\n",
    "    \n",
    "    for dir_name in dir_list:\n",
    "        dir_path = os.path.join(path,dir_name) #dir_path = '/tmp/CroppedYale/Yale01'\n",
    "        files = os.listdir(dir_path)\n",
    "        for f in files:\n",
    "            ori_path = os.path.join(dir_path,f) #dir_path = '/tmp/CroppedYale/Yale01'\n",
    "            if str(f).startswith(dir_name+\"-\"+str(14)+\"_\"): #自然光\n",
    "                ds_dir = \"./1210-test results/simulation_en_de0219/AR/selected/3-se/val_1_nature/\"\n",
    "                if not os.path.exists(ds_dir):\n",
    "                    os.makedirs(ds_dir)\n",
    "                    print(\"create success!\")\n",
    "                shutil.move(ori_path, ds_dir)\n",
    "            elif str(f).startswith(dir_name+\"-\"+str(15)+\"_\") or str(f).startswith(dir_name+\"-\"+str(16)+\"_\") or str(f).startswith(dir_name+\"-\"+str(17)+\"_\"): #emotions\n",
    "                ds_dir = \"./1210-test results/simulation_en_de0219/AR/selected/3-se/val_2_emotions/\"\n",
    "                if not os.path.exists(ds_dir):\n",
    "                    os.makedirs(ds_dir)\n",
    "                    print(\"create success!\")\n",
    "                shutil.move(ori_path, ds_dir)\n",
    "                \n",
    "            elif str(f).startswith(dir_name+\"-\"+str(18)+\"_\") or str(f).startswith(dir_name+\"-\"+str(19)+\"_\") or str(f).startswith(dir_name+\"-\"+str(20)+\"_\"): #emotions\n",
    "                ds_dir = \"./1210-test results/simulation_en_de0219/AR/selected/3-se/val_3_lights/\"\n",
    "                if not os.path.exists(ds_dir):\n",
    "                    os.makedirs(ds_dir)\n",
    "                    print(\"create success!\")\n",
    "                shutil.move(ori_path, ds_dir)\n",
    "            else:\n",
    "                ds_dir = \"./1210-test results/simulation_en_de0219/AR/selected/3-se/val_4_occulusions/\"\n",
    "                if not os.path.exists(ds_dir):\n",
    "                    os.makedirs(ds_dir)\n",
    "                    print(\"create success!\")\n",
    "                shutil.move(ori_path, ds_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88dca08",
   "metadata": {},
   "outputs": [],
   "source": [
    "expre_dir = \"./1210-test results/simulation_en_de0219/AR/dbf8_convert (copy)\"\n",
    "root_dir = os.walk(expre_dir)\n",
    "\n",
    "for path, dir_list,file_list in root_dir:\n",
    "    \n",
    "    for dir_name in dir_list:\n",
    "        dir_path = os.path.join(path,dir_name) #dir_path = '/tmp/CroppedYale/Yale01'\n",
    "\n",
    "        files = os.listdir(dir_path)\n",
    "        if len(files)==13:\n",
    "            dst_file_path = \"./1210-test results/simulation_en_de0219/AR/val_selected/\"\n",
    "            if os.path.exists(dst_file_path):\n",
    "                shutil.move(dir_path, dst_file_path)\n",
    "                #os.remove(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df06de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"./1210-test results/simulation_en_de0219/AR/tr_selected/\"\n",
    "val_dir = \"./1210-test results/simulation_en_de0219/AR/val_selected/\"\n",
    "train_root_dir = os.walk(train_dir)\n",
    "val_root_dir = os.walk(val_dir)\n",
    "\n",
    "for (tr_path, tr_dir_list,tr_file_list), (val_path, val_dir_list,val_file_list) in zip(train_root_dir,val_root_dir):\n",
    "    \n",
    "    for tr_dir_name in tr_dir_list:\n",
    "        tr_dir_path = os.path.join(tr_path,tr_dir_name) #dir_path = '/tmp/CroppedYale/Yale01'\n",
    "        val_dir_path = os.path.join(val_path,tr_dir_name) #dir_path = '/tmp/CroppedYale/Yale01'   \n",
    "        if tr_dir_name in val_dir_list:\n",
    "            shutil.move(tr_dir_path, \"./1210-test results/simulation_en_de0219/AR/train_se/\")\n",
    "            shutil.move(val_dir_path, \"./1210-test results/simulation_en_de0219/AR/val_se/\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5db740",
   "metadata": {},
   "outputs": [],
   "source": [
    "#expre_dir = \"./1210-test results/simulation_en_de0219/AR/dbf1_convert (copy)\"\n",
    "expre_dir = \"./1210-test results/simulation_en_de0219/AR/nature_occulus\"\n",
    "root_dir = os.walk(expre_dir)\n",
    "\n",
    "for path, dir_list,file_list in root_dir:\n",
    "    for file_name in file_list:\n",
    "        #print(file_name)\n",
    "        #print(len(dir_list))\n",
    "        for i in range(len(file_list)):\n",
    "            if i<10:\n",
    "                dir_name = \"m-00\"+str(i)\n",
    "                ori_file_path = os.path.join(path, file_name)\n",
    "                dst_file_path = os.path.join(path, dir_name + \"/\" + file_name)\n",
    "                if not os.path.exists(os.path.join(path, dir_name)):\n",
    "                  print(os.path.join(path, dir_name))\n",
    "                  os.makedirs(os.path.join(path, dir_name))\n",
    "                #print(dst_file_path)\n",
    "                if str(file_name).startswith(dir_name+\"-\"):\n",
    "                    shutil.move(ori_file_path, dst_file_path)\n",
    "            if i<10:\n",
    "                dir_name = \"w-00\"+str(i)\n",
    "                ori_file_path = os.path.join(path, file_name)\n",
    "                dst_file_path = os.path.join(path, dir_name + \"/\" + file_name)\n",
    "                if not os.path.exists(os.path.join(path, dir_name)):\n",
    "                  print(os.path.join(path, dir_name))\n",
    "                  os.makedirs(os.path.join(path, dir_name))\n",
    "                #print(dst_file_path)\n",
    "                if str(file_name).startswith(dir_name+\"-\"):\n",
    "                    shutil.move(ori_file_path, dst_file_path)\n",
    "                    \n",
    "            if i>9 and i<61:\n",
    "                dir_name = \"w-0\"+str(i)\n",
    "                ori_file_path = os.path.join(path, file_name)\n",
    "                dst_file_path = os.path.join(path, dir_name + \"/\" + file_name)\n",
    "                if not os.path.exists(os.path.join(path, dir_name)):\n",
    "                  print(os.path.join(path, dir_name))\n",
    "                  os.makedirs(os.path.join(path, dir_name))\n",
    "                #print(dst_file_path)\n",
    "                if str(file_name).startswith(dir_name+\"-\"):\n",
    "                    shutil.move(ori_file_path, dst_file_path)\n",
    "            \n",
    "            if i>9 and i<77:\n",
    "                dir_name = \"m-0\"+str(i)\n",
    "                ori_file_path = os.path.join(path, file_name)\n",
    "                dst_file_path = os.path.join(path, dir_name + \"/\" + file_name)\n",
    "                if not os.path.exists(os.path.join(path, dir_name)):\n",
    "                  print(os.path.join(path, dir_name))\n",
    "                  os.makedirs(os.path.join(path, dir_name))\n",
    "                #print(dst_file_path)\n",
    "                if str(file_name).startswith(dir_name+\"-\"):\n",
    "                    shutil.move(ori_file_path, dst_file_path)\n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65bd3d36",
   "metadata": {},
   "source": [
    "## Train:val:test ===2:1:1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8897d46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_list = []\n",
    "val_list = []\n",
    "test_list = []\n",
    "expre_dir = \"./1210-test results/simulation_en_de0219/AR/nature_occulus\"\n",
    "expre_dir_dataset = \"./1210-test results/simulation_en_de0219/AR/\"\n",
    "train_dir = os.path.join(expre_dir_dataset, \"train\")\n",
    "val_dir = os.path.join(expre_dir_dataset, \"val\")\n",
    "test_dir = os.path.join(expre_dir_dataset, \"test\")\n",
    "\n",
    "\n",
    "train_files_num = 0\n",
    "train_nums = []\n",
    "class_names = []\n",
    "\n",
    "train_files_num = 0\n",
    "val_files_num = 0\n",
    "test_files_num = 0\n",
    "\n",
    "train_nums = []\n",
    "val_nums = []\n",
    "test_nums = []\n",
    "        \n",
    "\n",
    "#creat a database  train has 1205 faces, val has 604 faces, test has 605 faces, train val test all have 38 classes\n",
    "Cropped_dir = os.walk(expre_dir) \n",
    "for path,dir_list,file_list in Cropped_dir: \n",
    "  for dir_name in dir_list:\n",
    "    \n",
    "    dir_path = os.path.join(path,dir_name) #dir_path = '/tmp/CroppedYale/Yale01'\n",
    "    \n",
    "    #each subject has 64 pictures\n",
    "    files = os.listdir(dir_path)\n",
    "    if len(files)==14:\n",
    "        file_path = []\n",
    "        train_f_num = []\n",
    "        val_f_num = []\n",
    "        test_f_num = []\n",
    "        class_names.append(dir_name)\n",
    "\n",
    "        for f in files:\n",
    "          if str(f).startswith(dir_name+\"-\"): #get the 64 file in each subject\n",
    "            file_path.append(os.path.join(dir_path,f))\n",
    "\n",
    "        print(len(file_path))\n",
    "        print(dir_name)\n",
    "\n",
    "        #random each subject\n",
    "        random.shuffle(file_path)\n",
    "        file_len = len(file_path)\n",
    "\n",
    "        #get each subject's path \n",
    "        train_class_path = os.path.join(train_dir,dir_name)\n",
    "        val_class_path = os.path.join(val_dir,dir_name)\n",
    "        test_class_path = os.path.join(test_dir,dir_name)\n",
    "        \n",
    "\n",
    "        #create a new dir train_dir val_dir and test_dir\n",
    "        if not os.path.exists(train_class_path):\n",
    "          print(train_class_path)\n",
    "          os.makedirs(train_class_path)\n",
    "          print('create train_class_path success！\\n')\n",
    "\n",
    "        if not os.path.exists(val_class_path):\n",
    "          print(val_class_path)\n",
    "          os.makedirs(val_class_path)\n",
    "          print('create val_class_path success！\\n')\n",
    "\n",
    "        if not os.path.exists(test_class_path):\n",
    "          print(test_class_path)\n",
    "          os.makedirs(test_class_path)\n",
    "          print('create test_class_path success！\\n')\n",
    "        \n",
    "        \n",
    "\n",
    "        #copy the pic to the train dir \n",
    "        #pgm->jpg\n",
    "        #open file and img->array A_list\n",
    "        for tr_src_path in file_path[:int(file_len/2)]:\n",
    "          if os.path.exists(tr_src_path):\n",
    "            # create A_dic = {yale01:0...31, yale02:32...63....}\n",
    "            train_f_num.append(train_files_num)\n",
    "            train_files_num = train_files_num+1\n",
    "            \n",
    "            shutil.copy(tr_src_path, train_class_path)\n",
    "\n",
    "            tr_img = Image.open(tr_src_path)\n",
    "            \n",
    "            tr_img_convert_ndarray = np.array(tr_img)\n",
    "            tr_img_convert_ndarray = tr_img_convert_ndarray.flatten()\n",
    "\n",
    "            A_list.append(tr_img_convert_ndarray)\n",
    "\n",
    "        train_nums.append(train_f_num)\n",
    "\n",
    "        for val_src_path in file_path[int(file_len/2):int(file_len/4*3)]:\n",
    "          if os.path.exists(val_src_path):\n",
    "            val_f_num.append(val_files_num)\n",
    "            val_files_num = val_files_num+1\n",
    "            shutil.copy(val_src_path, val_class_path)\n",
    "\n",
    "            # validation dataset\n",
    "            val_img = Image.open(val_src_path)\n",
    "        \n",
    "            val_img_convert_ndarray = np.array(val_img)\n",
    "            val_img_convert_ndarray = val_img_convert_ndarray.flatten()\n",
    "            val_list.append(val_img_convert_ndarray)\n",
    "        val_nums.append(val_f_num)\n",
    "    \n",
    "\n",
    "        for te_src_path in file_path[int(file_len/4*3):]:\n",
    "          if os.path.exists(te_src_path):\n",
    "            shutil.copy(te_src_path, test_class_path)\n",
    "            test_f_num.append(test_files_num)\n",
    "            test_files_num = test_files_num+1\n",
    "            #pgmtojpg(te_src_path, test_class_path, crop_test_dir, dir_name)\n",
    "\n",
    "            test_img = Image.open(te_src_path)\n",
    "            \n",
    "            test_img_convert_ndarray = np.array(test_img)\n",
    "            test_img_convert_ndarray = test_img_convert_ndarray.flatten()\n",
    "            test_list.append(test_img_convert_ndarray)\n",
    "            #shutil.copy(te_src_path, test_class_path)\n",
    "        test_nums.append(test_f_num)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1cb80fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array(A_list)\n",
    "A = A.T\n",
    "\n",
    "# create A_dic = {yale01:0...31, yale02:32...63....}\n",
    "A_dict = dict(zip(class_names, train_nums))\n",
    "val_dict = dict(zip(class_names, val_nums))\n",
    "test_dict = dict(zip(class_names, test_nums))\n",
    "print(class_names)\n",
    "print(A_dict)\n",
    "print(val_dict)\n",
    "print(test_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fe65f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(A.shape)\n",
    "savePath = os.path.join(expre_dir_dataset,\"save\")\n",
    "if not os.path.exists(savePath):\n",
    "      print(savePath)\n",
    "      os.makedirs(savePath)\n",
    "      print('create savePath success！\\n')\n",
    "\n",
    "rng = np.random.RandomState(int(time()))\n",
    "RM = [30,80,120,480]\n",
    "Rn = 200*240 \n",
    "R_list = []\n",
    "for Rm in RM:\n",
    "  R = rng.randn(Rm, Rn) / np.sqrt(Rm)\n",
    "  R_list.append(R)\n",
    "  print(R.shape)\n",
    "  np.save(savePath+\"/R\" +str(Rm) +\".npy\" , R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10d8bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_sort = class_names.copy()\n",
    "class_sort.sort()\n",
    "print(class_names)\n",
    "print(class_sort)\n",
    "num_to_class = dict(zip(class_sort, np.arange(0, len(class_sort))))\n",
    "print(num_to_class)\n",
    "class_to_num = dict(zip(np.arange(0, len(class_sort)), class_sort))\n",
    "print(class_to_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0bf78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "D = []\n",
    "D_num=0\n",
    "D_num_list=[]\n",
    "D_label = []\n",
    "num=[]\n",
    "\n",
    "for i,name in zip(range(110),class_sort):\n",
    "  print(name)\n",
    "  num.append(i)\n",
    "  D_label.append(name)\n",
    "  print(A_dict[name])\n",
    "  print(A_dict[name][0])\n",
    "  print(A_dict[name][-1])\n",
    "  D_list=[]\n",
    "  for j in A_dict[name]:\n",
    "    #print(j)\n",
    "    D.append(A_list[j])\n",
    "    D_list.append(D_num)\n",
    "    D_num+=1\n",
    "  D_num_list.append(D_list)\n",
    "print(len(D))\n",
    "print(len(A_list))\n",
    "print(D_num_list)\n",
    "print(D_label)\n",
    "print(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e7bdcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "D_label2num = dict(zip(D_label,D_num_list))\n",
    "print(D_label2num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e55138",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(A_list))\n",
    "\n",
    "\n",
    "train_label = []\n",
    "for name in class_names:\n",
    "  for i in A_dict[name]:\n",
    "    train_label.append(num_to_class[name])\n",
    "\n",
    "print(train_label)\n",
    "\n",
    "val_label = []\n",
    "for name in class_names:\n",
    "  for i in val_dict[name]:\n",
    "    val_label.append(num_to_class[name])\n",
    "\n",
    "print(val_label)\n",
    "\n",
    "test_label = []\n",
    "for name in class_names:\n",
    "  for i in test_dict[name]:\n",
    "    test_label.append(num_to_class[name])\n",
    "\n",
    "print(test_label)\n",
    "\n",
    "# val_data split to 5 parts\n",
    "train_label = np.array(train_label)\n",
    "val_label = np.array(val_label)\n",
    "test_label = np.array(test_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74a19da",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "if not os.path.exists(savePath):\n",
    "    print(savePath)\n",
    "    os.makedirs(savePath)\n",
    "    print('create' + savePath + 'success！\\n')\n",
    "\n",
    "print(np.array(D).shape)\n",
    "np.save(savePath+\"/D.npy\", np.array(D).T) #(32256,1205)\n",
    "np.save(savePath+\"/D_label2num.npy\", D_label2num) \n",
    "np.save(savePath+\"/class2num.npy\", class_to_num)\n",
    "np.save(savePath+\"/num2class.npy\", num_to_class)\n",
    "\n",
    "np.save(savePath+\"/train.npy\", A_list) \n",
    "np.save(savePath+\"/val.npy\", val_list)\n",
    "np.save(savePath+\"/test.npy\", test_list)\n",
    "np.save(savePath+\"/train_label.npy\", train_label) \n",
    "np.save(savePath+\"/val_label.npy\", val_label)\n",
    "np.save(savePath+\"/test_label.npy\", test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f070e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.array(A_list)\n",
    "val_data = np.array(val_list)\n",
    "test_data = np.array(test_list)\n",
    "\n",
    "# get the Random Matrix R\n",
    "rng = np.random.RandomState(int(time()))\n",
    "DA = np.array(D).T\n",
    "print(DA.shape)\n",
    "RM = [30,80,120,480]\n",
    "Rn = 200*240\n",
    "for R in R_list:\n",
    "  #W = RD\n",
    "  W = np.matmul(R,DA/255.0)\n",
    "  W_norm= np.linalg.norm(W, axis=0)\n",
    "  W = W/W_norm\n",
    "  print(W.shape)\n",
    "  np.save(savePath+\"/D\" +str(R.shape[0]) +\".npy\" , W)\n",
    "\n",
    "  #y = Ry train\n",
    "  tr_y = np.matmul(R,train_data.T/255.0)\n",
    "  print(tr_y.shape)\n",
    "\n",
    "  np.save(savePath+\"/train\" +str(R.shape[0]) +\".npy\" , tr_y)\n",
    "\n",
    "  #y = Ry val\n",
    "  val_y = np.matmul(R,val_data.T/255.0)\n",
    "  print(val_y.shape)\n",
    "  np.save(savePath+\"/val\" +str(R.shape[0]) +\".npy\" , val_y)\n",
    "\n",
    "  #y = Ry test\n",
    "  te_y = np.matmul(R,test_data.T/255.0)\n",
    "  print(te_y.shape)\n",
    "  np.save(savePath+\"/test\" +str(R.shape[0]) +\".npy\" , te_y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
